{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Portfolio Assignment: Wordnet\n",
        "\n",
        "Ahmed Iqbal (axi180011)\n",
        "\n",
        "## Summary of Wordnet\n",
        "Wordnet is a semantic database that has relations between words, such as between synonyms. Each word has a sysnet, which contains  its definitions and examples of using it. This makes it a blend between a dictionary and a thesaurus, and it is availible in over 200 languages."
      ],
      "metadata": {
        "id": "AUPSm7qtMNNK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1egvag7oHdm4",
        "outputId": "c36337d2-047c-4ffe-a5d2-911dee44d7a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Noun is plane \n",
            "\n",
            "Synsets: \n",
            "Synset('airplane.n.01')\n",
            "Synset('plane.n.02')\n",
            "Synset('plane.n.03')\n",
            "Synset('plane.n.04')\n",
            "Synset('plane.n.05')\n",
            "Synset('plane.v.01')\n",
            "Synset('plane.v.02')\n",
            "Synset('plane.v.03')\n",
            "Synset('flat.s.01')\n",
            "\n",
            "Definition of airplane.n.01 : an aircraft that has a fixed wing and is powered by propellers or jets\n",
            "Examples of airplane.n.01 : ['the flight was delayed due to trouble with the airplane']\n",
            "Lemmas: ['airplane', 'aeroplane', 'plane']\n",
            "\n",
            "Hierarchy traversal:\n",
            "Synset('heavier-than-air_craft.n.01')\n",
            "Synset('aircraft.n.01')\n",
            "Synset('craft.n.02')\n",
            "Synset('vehicle.n.01')\n",
            "Synset('conveyance.n.03')\n",
            "Synset('instrumentality.n.03')\n",
            "Synset('artifact.n.01')\n",
            "Synset('whole.n.02')\n",
            "Synset('object.n.01')\n",
            "Synset('physical_entity.n.01')\n",
            "Synset('entity.n.01')\n",
            "\n",
            "Hypernyms: [Synset('heavier-than-air_craft.n.01')]\n",
            "Hyponyms: [Synset('airliner.n.01'), Synset('amphibian.n.02'), Synset('biplane.n.01'), Synset('bomber.n.01'), Synset('delta_wing.n.01'), Synset('fighter.n.02'), Synset('hangar_queen.n.01'), Synset('jet.n.01'), Synset('monoplane.n.01'), Synset('multiengine_airplane.n.01'), Synset('propeller_plane.n.01'), Synset('reconnaissance_plane.n.01'), Synset('seaplane.n.01'), Synset('ski-plane.n.01'), Synset('tanker_plane.n.01')]\n",
            "Meronyms: [Synset('accelerator.n.01'), Synset('escape_hatch.n.01'), Synset('fuselage.n.01'), Synset('hood.n.09'), Synset('landing_gear.n.01'), Synset('navigation_light.n.01'), Synset('pod.n.04'), Synset('radome.n.01'), Synset('windshield.n.01'), Synset('wing.n.02')]\n",
            "Holonyms: []\n",
            "Antonyms: []\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "noun = 'plane'\n",
        "\n",
        "synsets = wn.synsets(noun)\n",
        "\n",
        "print(\"Noun is\", noun, \"\\n\\nSynsets: \")\n",
        "for set in synsets:\n",
        "  print(set)\n",
        "\n",
        "synset = synsets[0]\n",
        "\n",
        "# printing the definition, examples, and lemmas of the word\n",
        "print(\"\\nDefinition of\", synset.name(), \":\", synset.definition())\n",
        "print(\"Examples of\", synset.name(), \":\", synset.examples())\n",
        "print(\"Lemmas:\", synset.lemma_names())\n",
        "print()\n",
        "\n",
        "\n",
        "# getting a list of all of the items in the traveral of hieracrchy and printing them\n",
        "print(\"Hierarchy traversal:\")\n",
        "lambda_func = lambda x: x.hypernyms()\n",
        "traversal_list = list(synset.closure(lambda_func))\n",
        "for item in traversal_list:\n",
        "  print(item)\n",
        "\n",
        "# printing the hypernyms, hyponyms, meronyms, holonyms, and antonyms\n",
        "print(\"\\nHypernyms:\", synset.hypernyms())\n",
        "print(\"Hyponyms:\", synset.hyponyms())\n",
        "print(\"Meronyms:\", synset.part_meronyms())\n",
        "print(\"Holonyms:\", synset.part_holonyms())\n",
        "print(\"Antonyms:\", synset.lemmas()[0].antonyms())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How WordNet is organized for nouns\n",
        "Nouns in wordnet are organized in a descending order in terms of specificity. That is, the lower down in the hierarchy a noun is, the more specific it is at describing an object. FOr example, vehicle is lower down in the hierarchy than entity."
      ],
      "metadata": {
        "id": "hAfhwr-0UoCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "verb = 'fly'\n",
        "\n",
        "synsets = wn.synsets(verb, pos=wn.VERB)\n",
        "\n",
        "# printing all synsets\n",
        "print(\"Verb is\", verb, \"\\n\\nSynsets: \")\n",
        "for set in synsets:\n",
        "  print(set)\n",
        "\n",
        "# picking a synset\n",
        "synset = synsets[0]\n",
        "\n",
        "# printing the definition, examples, and lemmas of the word\n",
        "print(\"\\nDefinition of\", synset.name(), \":\", synset.definition())\n",
        "print(\"Examples of\", synset.name(), \":\", synset.examples())\n",
        "print(\"Lemmas: \", synset.lemma_names())\n",
        "\n",
        "# getting a list of all of the items in the traveral of hieracrchy and printing them\n",
        "print(\"\\nHierarchy traversal:\")\n",
        "lambda_func = lambda x: x.hypernyms()\n",
        "traversal_list = list(synset.closure(lambda_func))\n",
        "for item in traversal_list:\n",
        "  print(item)\n",
        "\n",
        "# finding and printing the different forms of the word\n",
        "forms_list = []\n",
        "for set in synsets:\n",
        "  for name in set.lemma_names():\n",
        "    forms_list.append(wn.morphy(name))\n",
        "print(\"\\nDifferent forms of the word:\", forms_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAflbmW6uuwV",
        "outputId": "b491b312-881a-48fa-bafc-4062271b0783"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verb is fly \n",
            "\n",
            "Synsets: \n",
            "Synset('fly.v.01')\n",
            "Synset('fly.v.02')\n",
            "Synset('fly.v.03')\n",
            "Synset('fly.v.04')\n",
            "Synset('fly.v.05')\n",
            "Synset('fly.v.06')\n",
            "Synset('fly.v.07')\n",
            "Synset('fly.v.08')\n",
            "Synset('fly.v.09')\n",
            "Synset('fly.v.10')\n",
            "Synset('flee.v.01')\n",
            "Synset('fly.v.12')\n",
            "Synset('fly.v.13')\n",
            "Synset('vanish.v.05')\n",
            "\n",
            "Definition of fly.v.01 : travel through the air; be airborne\n",
            "Examples of fly.v.01 : ['Man cannot fly']\n",
            "Lemmas:  ['fly', 'wing']\n",
            "\n",
            "Hierarchy traversal:\n",
            "Synset('travel.v.01')\n",
            "\n",
            "Different forms of the word: ['fly', 'wing', 'fly', 'fly', 'aviate', 'pilot', 'fly', 'fly', 'fly', 'fly', 'fly', 'fell', 'vanish', 'fly', 'fly', 'flee', 'fly', 'take_flight', 'fly', 'fly', 'vanish', 'fly', 'vaporize']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How WordNet is organized for verbs\n",
        "Verbs in Wordnet also seem to be organized in a descending order in terms of specificity. However, unlike with the hierarchy for nouns, there are not many results for my chosen verb or some others that I have tried, so my observations hold less weight."
      ],
      "metadata": {
        "id": "J8znDAe8VSSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.wsd import lesk\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "word1, word2 = \"snow\", \"frost\"\n",
        "print(f\"The two words are {word1} and {word2}\")\n",
        "\n",
        "# getting synset for the two words\n",
        "synset1 = wn.synsets(word1)[0]\n",
        "synset2 = wn.synsets(word2)[0]\n",
        "\n",
        "# calculating the wu-palmer metric over the two synsets\n",
        "print(f\"\\nThe Wu-Palmer similarity metric: {wn.wup_similarity(synset1, synset2)}\")\n",
        "\n",
        "# splitting example sentences\n",
        "sent1, sent2 = \"The snow is falling heavily\", \"The morning frost is everywhere\"\n",
        "split_sent1 = sent1.split(\" \")\n",
        "split_sent2 = sent2.split(\" \")\n",
        "\n",
        "# running the lesk algorithm for both words over their respective sentences\n",
        "lesk1 = lesk(split_sent1, word1)\n",
        "lesk2 = lesk(split_sent2, word2)\n",
        "\n",
        "# printing the output of the lesk algorithm\n",
        "print(f\"\\nThe output of the lesk algorithm for \\\"{word1}\\\" over \\\"{sent1}\\\" is {lesk1} and for \\\"{word2}\\\" over \\\"{sent2}\\\" is {lesk2}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q86jeav1FWCI",
        "outputId": "b8d954c9-54cf-42ed-a1af-fe3a63a58750"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The two words are snow and frost\n",
            "\n",
            "The Wu-Palmer similarity metric: 0.23529411764705882\n",
            "\n",
            "The output of the lesk algorithm for \"snow\" over \"The snow is falling heavily\" is Synset('snow.v.01') and for \"frost\" over \"The morning frost is everywhere\" is Synset('frost.v.04')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observations on Wu-Palmer similarity metric and Lesk algorithm\n",
        "From our results, we can see that there a low relationship between snow and frost, which is quite suprising. Since it calculates relatedness using the depths of the words in the hierarchy, I thought the score would be higher. As far as the Lesk algorithm goes, it seems to correctly indentify which synset of a word is being used in a given sentence."
      ],
      "metadata": {
        "id": "0hKnwhJnXaJF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# About SentiWordNet\n",
        "\n",
        "SentiWordNet is a lexical resource that is built on top of WordNet. It can assign positive, negative, and overall scores to synsets and and analyze a text for positive/negative or objective/subjective tones. Thus, it is able to capture the human sentiments that are covneyed with the words, not just the dictionary definitions."
      ],
      "metadata": {
        "id": "9paPsxJ1bFT8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('sentiwordnet')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.corpus import sentiwordnet as swn\n",
        "\n",
        "emotional = \"passionate\"\n",
        "\n",
        "# finding all synsets for \"passionate\"\n",
        "synsets = swn.senti_synsets(emotional)\n",
        "\n",
        "# printing scores of all synsets\n",
        "for synset in synsets:\n",
        "  print(f\"\\nThe word {synset.synset.name()} has a positive score of {synset.pos_score()}, a negative score of {synset.pos_score()}, and an overall score of {synset.obj_score()}\\n\")\n",
        "\n",
        "sent = \"You would be hard pressed to find a man more passionate about a cause.\"\n",
        "split_sent = sent.split(\" \")\n",
        "\n",
        "# printing the polarity for each word in the example sentence\n",
        "for word in split_sent:\n",
        "  try:\n",
        "    synset = list(swn.senti_synsets(word))[0]\n",
        "    print(f\"The polarity of {word} is {synset.pos_score() - synset.neg_score()}\")\n",
        "  except:\n",
        "    print(f\"There is no synset for {word}\")\n",
        "    \n",
        "print()\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQk4dbkmO5Rs",
        "outputId": "b7ca7f96-6c42-423c-84b5-e64a8f010507"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The word passionate.a.01 has a positive score of 0.375, a negative score of 0.375, and an overall score of 0.25\n",
            "\n",
            "There is no synset for You\n",
            "There is no synset for would\n",
            "The polarity of be is 0.0\n",
            "The polarity of hard is -0.75\n",
            "The polarity of pressed is 0.0\n",
            "There is no synset for to\n",
            "The polarity of find is 0.625\n",
            "The polarity of a is 0.0\n",
            "The polarity of man is 0.0\n",
            "The polarity of more is 0.0\n",
            "The polarity of passionate is 0.0\n",
            "The polarity of about is 0.0\n",
            "The polarity of a is 0.0\n",
            "There is no synset for cause.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
            "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utility in NLP application\n",
        "\n",
        "The ability to know the tone or objectiveness of a piece of text is incredibly useful. It can be used to filter news by analyzing how biased it is, or it could be used to combat cyberbullying by looking at the sentiments in addition to commonly used speech in bullying.\n"
      ],
      "metadata": {
        "id": "-iVImXvObOz1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# About collocations\n",
        "\n",
        "A collocation is essentially a series of words that occurs in a predictable manner and often enough that it is not by chance alone. They can be made up of any kind of word. An example is saying something has a \"rich history\". We would not say \"wealthy history\" because it doesn't have the same meaning colloquially and it sounds off."
      ],
      "metadata": {
        "id": "7GJihcA8bP1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from nltk.text import Text\n",
        "from nltk.corpus import inaugural\n",
        "nltk.download('inaugural')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# getting text4 and a collocation\n",
        "text4 = Text(inaugural.words())\n",
        "collocation = list(text4.collocation_list())[0]\n",
        "\n",
        "# printing the collocation\n",
        "print(f\"\\nCollocation: {collocation}\")\n",
        "\n",
        "# finding the number f tokens in the text\n",
        "tokens = nltk.word_tokenize(inaugural.raw())\n",
        "num_of_tokens = len(tokens)\n",
        "\n",
        "# combining the collocation and tokens into strings to search through them easier\n",
        "text4 = \" \".join(tokens)\n",
        "colloc = \" \".join(collocation)\n",
        "\n",
        "# caluclating and printing the pmi according to the equation log2(P(x,y)/(P(x)*P(y)))\n",
        "print(f\"The PMI is {math.log2((text4.count(colloc)/num_of_tokens)/((text4.count(collocation[0])/num_of_tokens)*(text4.count(collocation[1])/num_of_tokens)))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HULKkUL8I-VK",
        "outputId": "4e00d0d5-d385-46af-bdbd-8dce7341a9ee"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]   Package inaugural is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collocation: ('United', 'States')\n",
            "The PMI is 8.738235157306907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results of mutual information formula\n",
        "\n",
        "Based on the result of 8.74 from the mutual information formula, we can safely say that there is a strong correlation between the words \"United\" and \"States\". This is because the number is positive and quite high. Had it been zero, we would say that there is no correlation. And had the number been negative, we would say that there is a anegative correlation. Thus, put together, they are very likely to be a collocation."
      ],
      "metadata": {
        "id": "RV8G970sbUGS"
      }
    }
  ]
}